{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Possible performance improvement - calculate x features once\n",
      "\n",
      "This is a very basic PoC.\n",
      "\n",
      "It is not totally accurate due to the bifurcation of fctype it is a general gauge for now.\n",
      "\n",
      "I am adding this because one or more of you will be able to down this quicker than me, if it is valid.\n",
      "\n",
      "In all funcs in feature_calculators.py only x is passed in this means that the following functions are\n",
      "possibly calculated the following amount of times for x:\n",
      "\n",
      "np.var:  3\n",
      "len: 26\n",
      "np.mean: 13\n",
      "np.asarray: 9\n",
      "# once_time, saves, fc_time = once_saving(pd.Series, 'pd.Series', 11)\n",
      "# once_time, saves, fc_time = once_saving(np.diff, 'np.diff', 4)\n",
      "max: 8\n",
      "min: 8\n",
      "\n",
      "On a small timeseries not really any performance saving.\n",
      "On a LONG timeseries a big performance saving.\n",
      "On a lot of timeseries, probably a lot too.\n",
      "\n",
      "If it is valid, however I am fairly certain even if some things do not match some fctypes, calculating\n",
      "these features for x once, at scale should be a fairly large saving.\n",
      "\n",
      "Passing x, np_x_std or x, np_x_mean etc where appropriate.  I never really got to dig much this weekend\n",
      "as there was surf :)\n",
      "\n",
      "And the digging I did do, I am still solving for x :)\n",
      "\n",
      "NOTE: if you are on Windows and do not have /tmp adjust path = '/tmp/.. below.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "INFO = '''\n",
    "Possible performance improvement - calculate x features once\n",
    "\n",
    "This is a very basic PoC.\n",
    "\n",
    "It is not totally accurate due to the bifurcation of fctype it is a general gauge for now.\n",
    "\n",
    "I am adding this because one or more of you will be able to down this quicker than me, if it is valid.\n",
    "\n",
    "In all funcs in feature_calculators.py only x is passed in this means that the following functions are\n",
    "possibly calculated the following amount of times for x:\n",
    "\n",
    "np.var:  3\n",
    "len: 26\n",
    "np.mean: 13\n",
    "np.asarray: 9\n",
    "# once_time, saves, fc_time = once_saving(pd.Series, 'pd.Series', 11)\n",
    "# once_time, saves, fc_time = once_saving(np.diff, 'np.diff', 4)\n",
    "max: 8\n",
    "min: 8\n",
    "\n",
    "On a small timeseries not really any performance saving.\n",
    "On a LONG timeseries a big performance saving.\n",
    "On a lot of timeseries, probably a lot too.\n",
    "\n",
    "If it is valid, however I am fairly certain even if some things do not match some fctypes, calculating\n",
    "these features for x once, at scale should be a fairly large saving.\n",
    "\n",
    "Passing x, np_x_std or x, np_x_mean etc where appropriate.  I never really got to dig much this weekend\n",
    "as there was surf :)\n",
    "\n",
    "And the digging I did do, I am still solving for x :)\n",
    "\n",
    "NOTE: if you are on Windows and do not have /tmp adjust path = '/tmp/.. below.\n",
    "\n",
    "Play with multiple_timeseries = 100\n",
    "\n",
    "'''\n",
    "print(INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing - /tmp/skyline/stats.statsd.bad_lines_seen/stats.statsd.bad_lines_seen.20161110.csv\n",
      "Time to create x df of 143900 length :: 0.177644 seconds\n",
      "\n",
      "####\n",
      "# np.std analysis\n",
      "\n",
      "Time to calculate np.std once for a timeseries with 143900 data points :: 0.001197 seconds\n",
      "Time to calculate np.std 5 times for a timeseries with 143900 data points :: 0.005420 seconds\n",
      "Calculating np.std once is saves :: 0.004223 seconds or 4.222870 milliseconds\n",
      "It is [-77.91316588] percent less efficient to calculate np.std 5 times\n",
      "Timeseries values sum :: 313.333333333\n",
      "\n",
      "####\n",
      "# np.var analysis\n",
      "\n",
      "Time to calculate np.var once for a timeseries with 143900 data points :: 0.001099 seconds\n",
      "Time to calculate np.var 3 times for a timeseries with 143900 data points :: 0.003738 seconds\n",
      "Calculating np.var once is saves :: 0.002639 seconds or 2.639294 milliseconds\n",
      "It is [-70.6039926] percent less efficient to calculate np.var 3 times\n",
      "Timeseries values sum :: 313.333333333\n",
      "\n",
      "####\n",
      "# len analysis\n",
      "\n",
      "Time to calculate len once for a timeseries with 143900 data points :: 0.000008 seconds\n",
      "Time to calculate len 26 times for a timeseries with 143900 data points :: 0.000035 seconds\n",
      "Calculating len once is saves :: 0.000027 seconds or 0.027180 milliseconds\n",
      "It is [-77.55102041] percent less efficient to calculate len 26 times\n",
      "Timeseries values sum :: 313.333333333\n",
      "\n",
      "####\n",
      "# np.mean analysis\n",
      "\n",
      "Time to calculate np.mean once for a timeseries with 143900 data points :: 0.001032 seconds\n",
      "Time to calculate np.mean 13 times for a timeseries with 143900 data points :: 0.010713 seconds\n",
      "Calculating np.mean once is saves :: 0.009681 seconds or 9.681225 milliseconds\n",
      "It is [-90.36809543] percent less efficient to calculate np.mean 13 times\n",
      "Timeseries values sum :: 313.333333333\n",
      "\n",
      "####\n",
      "# np.asarray analysis\n",
      "\n",
      "Time to calculate np.asarray once for a timeseries with 143900 data points :: 0.000023 seconds\n",
      "Time to calculate np.asarray 9 times for a timeseries with 143900 data points :: 0.000041 seconds\n",
      "Calculating np.asarray once is saves :: 0.000018 seconds or 0.017881 milliseconds\n",
      "It is [-43.60465116] percent less efficient to calculate np.asarray 9 times\n",
      "Timeseries values sum :: 313.333333333\n",
      "\n",
      "####\n",
      "# max analysis\n",
      "\n",
      "Time to calculate max once for a timeseries with 143900 data points :: 0.008400 seconds\n",
      "Time to calculate max 8 times for a timeseries with 143900 data points :: 0.066409 seconds\n",
      "Calculating max once is saves :: 0.058009 seconds or 58.009148 milliseconds\n",
      "It is [-87.35118834] percent less efficient to calculate max 8 times\n",
      "Timeseries values sum :: 313.333333333\n",
      "\n",
      "####\n",
      "# min analysis\n",
      "\n",
      "Time to calculate min once for a timeseries with 143900 data points :: 0.008582 seconds\n",
      "Time to calculate min 8 times for a timeseries with 143900 data points :: 0.067260 seconds\n",
      "Calculating min once is saves :: 0.058678 seconds or 58.677912 milliseconds\n",
      "It is [-87.2403929] percent less efficient to calculate min 8 times\n",
      "Timeseries values sum :: 313.333333333\n",
      "\n",
      "####\n",
      "# Overall analysis\n",
      "\n",
      "Total master features_calculator.py time    :: 0.153616 seconds\n",
      "Total performance_once method time          :: 0.020341 seconds\n",
      "Total time saved by performance_once method :: 0.133276 seconds\n",
      "It is [-86.75863011] percent less efficient to calculate values multiple times\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import requests\n",
    "\n",
    "\n",
    "multiple_timeseries = 100\n",
    "\n",
    "\n",
    "data_source = 'https://raw.githubusercontent.com/earthgecko/skyline/795a22c3a09f3bc8487d9cc7ff7a5401da1cb217/tests/baseline/stats.statsd.bad_lines_seen.20161110.csv'\n",
    "savings = []\n",
    "fc_times = []\n",
    "once_times = []\n",
    "\n",
    "\n",
    "def create_x():\n",
    "\n",
    "    path = '/tmp/skyline/stats.statsd.bad_lines_seen'\n",
    "    tmp_csv = '%s/stats.statsd.bad_lines_seen.20161110.csv' % path\n",
    "\n",
    "    if not os.path.isfile(tmp_csv):\n",
    "        print('Getting data source - %s' % data_source)\n",
    "        r = None\n",
    "        http_status_code = 0\n",
    "        try:\n",
    "            r = requests.get(data_source, timeout=10)\n",
    "            http_status_code = r.status_code\n",
    "            if int(http_status_code) == 200:\n",
    "                print('Got data source')\n",
    "        except:\n",
    "            print(traceback.format_exc())\n",
    "            print('error :: could not retrieve %s' % data_source)\n",
    "\n",
    "        try:\n",
    "            if not os.path.isdir(path):\n",
    "                print('Need to create dir - %s' % path)\n",
    "                try:\n",
    "                    print('Making dir - %s' % path)\n",
    "                    os.makedirs(path, mode=0o755)\n",
    "                    return True\n",
    "                # Python >2.5\n",
    "                except OSError as exc:\n",
    "                    if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "                        pass\n",
    "                    else:\n",
    "                        raise\n",
    "            else:\n",
    "                print('dir exists - %s' % path)\n",
    "        except:\n",
    "            print(traceback.format_exc())\n",
    "            print('error :: could not create %s' % path)\n",
    "\n",
    "        with open(tmp_csv, 'w') as fh:\n",
    "            print('Creating - %s' % tmp_csv)\n",
    "            fh.write(str(r.text))\n",
    "    else:\n",
    "        print('Using existing - %s' % tmp_csv)\n",
    "\n",
    "    ts_count = 0\n",
    "    start_df = timer()\n",
    "    df = pd.DataFrame()\n",
    "    # df.columns = ['metric', 'timestamp', 'value']\n",
    "    df_new = pd.read_csv(tmp_csv, delimiter=',', header=None, names=['metric', 'timestamp', 'value'])\n",
    "    df_new.columns = ['metric', 'timestamp', 'value']\n",
    "    while ts_count < multiple_timeseries:\n",
    "        df_append = df.append(df_new)\n",
    "        df = df_append\n",
    "        ts_count += 1\n",
    "    end_df = timer()\n",
    "    df_time = end_df - start_df\n",
    "    x = df['value']\n",
    "    print('Time to create x df of %s length :: %.6f seconds' % (str(len(x)), df_time))\n",
    "    return x\n",
    "\n",
    "\n",
    "def once_saving(x, func_object, func_name, times_func_used):\n",
    "    \"\"\"\n",
    "    This method calculates time taken to calculate np values multiple times\n",
    "\n",
    "    :param func: A numpy function or other function object\n",
    "    :param func_name: The numpy function as a string\n",
    "    :param times_func_used: The numpy function as a string\n",
    "\n",
    "    :return: A list with the length of all sub-sequences where the array is either True or False. If no ones or Trues\n",
    "\n",
    "    contained, a the list [0] is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    start_one = timer()\n",
    "    func_result = func_object(x)\n",
    "    end_one = timer()\n",
    "    once_time = end_one - start_one\n",
    "\n",
    "    # Calculate features_calculator.py time\n",
    "    start = timer()\n",
    "    count = 0\n",
    "    while count != times_func_used:\n",
    "        count += 1\n",
    "        func_result = func_object(x)\n",
    "    end = timer()\n",
    "    x_len = len(x)\n",
    "    fc_time = end - start\n",
    "    once_saves = fc_time - once_time\n",
    "    print('\\n####\\n# %s analysis\\n' % (func_name))\n",
    "    print(\n",
    "        'Time to calculate %s once for a timeseries with %s data points :: %.6f seconds' %\n",
    "        (func_name, str(x_len), once_time))\n",
    "    print(\n",
    "        'Time to calculate %s %s times for a timeseries with %s data points :: %.6f seconds' %\n",
    "        (func_name, str(count), str(x_len), fc_time))\n",
    "    print(\n",
    "        'Calculating %s once is saves :: %.6f seconds or %.6f milliseconds' %\n",
    "        (func_name, once_saves, (once_saves * 1000)))\n",
    "    if once_time == 0:\n",
    "        once_time = 0.000001\n",
    "    if fc_time == 0:\n",
    "        fc_time = 0.000001\n",
    "    a = np.array([float(fc_time), float(once_time)], dtype=float)\n",
    "    diff = np.diff(a) / np.abs(a[:-1]) * 100.\n",
    "    print(\n",
    "        'It is %s percent less efficient to calculate %s %s times' %\n",
    "        (str(diff), func_name, str(times_func_used)))\n",
    "    print('Timeseries values sum :: %s' % (str(sum(x))))\n",
    "\n",
    "    return once_time, once_saves, fc_time\n",
    "\n",
    "\n",
    "def append_times(once_time, saves, fc_time):\n",
    "    savings.append(saves)\n",
    "    fc_times.append(fc_time)\n",
    "    once_times.append(once_time)\n",
    "\n",
    "\n",
    "def calc_saving(x, func_object, func_name, fc_times):\n",
    "    once_time, saves, fc_time = once_saving(x, func_object, func_name, fc_times)\n",
    "    append_times(once_time, saves, fc_time)\n",
    "\n",
    "x = create_x()\n",
    "\n",
    "calc_saving(x, np.std, 'np.std', 5)\n",
    "# ≈ (0.07 to 0.2) × average length of a human blink of an eye ( 100 to 400 ms )\n",
    "# ≈ time for a nerve impulse to travel the length of a human ( 1 average human heights/maximum speed of a nerve impulse )\n",
    "\n",
    "calc_saving(x, np.var, 'np.var', 3)\n",
    "calc_saving(x, len, 'len', 26)\n",
    "calc_saving(x, np.mean, 'np.mean', 13)\n",
    "calc_saving(x, np.asarray, 'np.asarray', 9)\n",
    "# I could not get pd.Series or np.diff to carry through\n",
    "# once_time, saves, fc_time = once_saving(pd.Series, 'pd.Series', 11)\n",
    "# once_time, saves, fc_time = once_saving(np.diff, 'np.diff', 4)\n",
    "calc_saving(x, max, 'max', 8)\n",
    "calc_saving(x, max, 'min', 8)\n",
    "\n",
    "print('\\n####\\n# Overall analysis\\n')\n",
    "print 'Total master features_calculator.py time    :: %.6f seconds' % sum(fc_times)\n",
    "print 'Total performance_once method time          :: %.6f seconds' % sum(once_times)\n",
    "print 'Total time saved by performance_once method :: %.6f seconds' % sum(savings)\n",
    "a = np.array([float(sum(fc_times)), float(sum(once_times))], dtype=float)\n",
    "diff = np.diff(a) / np.abs(a[:-1]) * 100.\n",
    "print(\n",
    "    'It is %s percent less efficient to calculate values multiple times' %\n",
    "    (str(diff)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the above is set to multiple_timeseries 100 try change to:\n",
    "# multiple_timeseries = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
