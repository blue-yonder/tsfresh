{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to create a timeseries with 100 data points :: 0.044883 seconds\n",
      "Time to calculate features for a timeseries with 100 data points :: 0.363165 seconds\n",
      "\n",
      "isinstance was calculated 120 times which took :: 0.000984 seconds\n",
      "len was calculated 27 times which took :: 0.000125 seconds\n",
      "max was calculated 32 times which took :: 0.001106 seconds\n",
      "min was calculated 33 times which took :: 0.001030 seconds\n",
      "np.array was calculated 2 times which took :: 0.000044 seconds\n",
      "np.asarray was calculated 15 times which took :: 0.000307 seconds\n",
      "np.mean was calculated 27 times which took :: 0.004518 seconds\n",
      "np.median was calculated 21 times which took :: 0.002105 seconds\n",
      "np.std was calculated 18 times which took :: 0.003210 seconds\n",
      "np.sum was calculated 1 times which took :: 0.000165 seconds\n",
      "np.var was calculated 3 times which took :: 0.000614 seconds\n",
      "Total function times took :: 0.014208 seconds\n",
      "Total function times for 10 timeseries would take :: 0.142080 seconds\n",
      "Total function times for 100 timeseries would take :: 1.420800 seconds\n",
      "Total function times for 1000 timeseries would take :: 14.208000 seconds\n",
      "Total function times for 10000 timeseries would take :: 142.080000 seconds\n",
      "Total function times for 100000 timeseries would take :: 1420.800000 seconds\n",
      "Total function times for 10000000 timeseries would take :: 142080.000000 seconds\n",
      "\n",
      "Time to create a timeseries with 1000 data points :: 0.119235 seconds\n",
      "Time to calculate features for a timeseries with 1000 data points :: 1.736729 seconds\n",
      "\n",
      "isinstance was calculated 120 times which took :: 0.000694 seconds\n",
      "len was calculated 27 times which took :: 0.000146 seconds\n",
      "max was calculated 32 times which took :: 0.002344 seconds\n",
      "min was calculated 33 times which took :: 0.002280 seconds\n",
      "np.array was calculated 2 times which took :: 0.000026 seconds\n",
      "np.asarray was calculated 15 times which took :: 0.000224 seconds\n",
      "np.mean was calculated 27 times which took :: 0.003228 seconds\n",
      "np.median was calculated 21 times which took :: 0.001677 seconds\n",
      "np.std was calculated 18 times which took :: 0.002101 seconds\n",
      "np.sum was calculated 1 times which took :: 0.000106 seconds\n",
      "np.var was calculated 3 times which took :: 0.000427 seconds\n",
      "Total function times took :: 0.013253 seconds\n",
      "Total function times for 10 timeseries would take :: 0.132530 seconds\n",
      "Total function times for 100 timeseries would take :: 1.325300 seconds\n",
      "Total function times for 1000 timeseries would take :: 13.253000 seconds\n",
      "Total function times for 10000 timeseries would take :: 132.530000 seconds\n",
      "Total function times for 100000 timeseries would take :: 1325.300000 seconds\n",
      "Total function times for 10000000 timeseries would take :: 132530.000000 seconds\n",
      "\n",
      "Time to create a timeseries with 5000 data points :: 0.677229 seconds\n",
      "Time to calculate features for a timeseries with 5000 data points :: 38.763440 seconds\n",
      "\n",
      "isinstance was calculated 120 times which took :: 0.001065 seconds\n",
      "len was calculated 27 times which took :: 0.000126 seconds\n",
      "max was calculated 32 times which took :: 0.012740 seconds\n",
      "min was calculated 33 times which took :: 0.012737 seconds\n",
      "np.array was calculated 2 times which took :: 0.000050 seconds\n",
      "np.asarray was calculated 15 times which took :: 0.000252 seconds\n",
      "np.mean was calculated 27 times which took :: 0.004918 seconds\n",
      "np.median was calculated 21 times which took :: 0.003355 seconds\n",
      "np.std was calculated 18 times which took :: 0.002897 seconds\n",
      "np.sum was calculated 1 times which took :: 0.000144 seconds\n",
      "np.var was calculated 3 times which took :: 0.000631 seconds\n",
      "Total function times took :: 0.038915 seconds\n",
      "Total function times for 10 timeseries would take :: 0.389150 seconds\n",
      "Total function times for 100 timeseries would take :: 3.891500 seconds\n",
      "Total function times for 1000 timeseries would take :: 38.915000 seconds\n",
      "Total function times for 10000 timeseries would take :: 389.150000 seconds\n",
      "Total function times for 100000 timeseries would take :: 3891.500000 seconds\n",
      "Total function times for 10000000 timeseries would take :: 389150.000000 seconds\n",
      "\n",
      "Time to create a timeseries with 10000 data points :: 0.973279 seconds\n",
      "Time to calculate features for a timeseries with 10000 data points :: 164.063783 seconds\n",
      "\n",
      "isinstance was calculated 120 times which took :: 0.000853 seconds\n",
      "len was calculated 27 times which took :: 0.000096 seconds\n",
      "max was calculated 32 times which took :: 0.021726 seconds\n",
      "min was calculated 33 times which took :: 0.023070 seconds\n",
      "np.array was calculated 2 times which took :: 0.000042 seconds\n",
      "np.asarray was calculated 15 times which took :: 0.000226 seconds\n",
      "np.mean was calculated 27 times which took :: 0.004781 seconds\n",
      "np.median was calculated 21 times which took :: 0.006200 seconds\n",
      "np.std was calculated 18 times which took :: 0.003018 seconds\n",
      "np.sum was calculated 1 times which took :: 0.000179 seconds\n",
      "np.var was calculated 3 times which took :: 0.000583 seconds\n",
      "Total function times took :: 0.060774 seconds\n",
      "Total function times for 10 timeseries would take :: 0.607740 seconds\n",
      "Total function times for 100 timeseries would take :: 6.077400 seconds\n",
      "Total function times for 1000 timeseries would take :: 60.774000 seconds\n",
      "Total function times for 10000 timeseries would take :: 607.740000 seconds\n",
      "Total function times for 100000 timeseries would take :: 6077.400000 seconds\n",
      "Total function times for 10000000 timeseries would take :: 607740.000000 seconds\n"
     ]
    }
   ],
   "source": [
    "from sys import version_info\n",
    "from os import path\n",
    "import warnings\n",
    "\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from tsfresh.feature_extraction import FeatureExtractionSettings\n",
    "from tsfresh.utilities.profiling import start_profiling, end_profiling\n",
    "\n",
    "from tsfresh import extract_features\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "python_version = int(version_info[0])\n",
    "\n",
    "fname_out = '/tmp/test_performance_varied_ts_len.timeseries.csv'\n",
    "debug_log = '/tmp/tsfresh.debug.log'\n",
    "\n",
    "\n",
    "def reset_log():\n",
    "    if path.isfile(debug_log):\n",
    "        with open(debug_log, 'w') as fh:\n",
    "            pass\n",
    "\n",
    "\n",
    "def dt2ut(dt):\n",
    "    epoch = pd.to_datetime('1970-01-01')\n",
    "    return (dt - epoch).total_seconds()\n",
    "\n",
    "\n",
    "def create_df(period):\n",
    "\n",
    "    start = timer()\n",
    "    rng = pd.date_range(1262304000, periods=period, freq='T', name='timestamp_obj')\n",
    "    ts = pd.Series(np.random.randn(len(rng)), rng)\n",
    "    df_ts = ts.to_frame(name=None)\n",
    "    df_ts.insert(0, 'id', 'test')\n",
    "    df_ts.reset_index\n",
    "    df_ts.columns = ['id', 'value']\n",
    "    df_ts['timestamp'] = df_ts.index\n",
    "    df_ts.columns = ['metric', 'value', 'timestamp']\n",
    "\n",
    "    df_ts.reset_index\n",
    "    df_ts = df_ts[['metric', 'timestamp', 'value']]\n",
    "    df_ts['timestamp'] = df_ts['timestamp'].apply(dt2ut).astype(int)\n",
    "\n",
    "    df_ts.to_csv(fname_out, index=False, header=False)\n",
    "    end = timer()\n",
    "    create_time = end - start\n",
    "    print(\n",
    "        '\\nTime to create a timeseries with %s data points :: %.6f seconds' %\n",
    "        (str(period), create_time))\n",
    "\n",
    "    return fname_out\n",
    "\n",
    "\n",
    "def calc_runtime(period):\n",
    "    \"\"\"\n",
    "    This method calculates time taken to extract features on a timeseries of\n",
    "    period length\n",
    "\n",
    "    :param df: a pandas Series\n",
    "    :param period: the number of samples in the timeseries\n",
    "\n",
    "    :return: A list with the length of all sub-sequences where the array is either True or False. If no ones or Trues\n",
    "\n",
    "    contained, a the list [0] is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    start = timer()\n",
    "    try:\n",
    "        fname_out = create_df(period)\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "        print('error :: could not read buf')\n",
    "\n",
    "    df = None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(fname_out, delimiter=',', header=None, names=['metric', 'timestamp', 'value'])\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "        print('error :: could not created df from buf')\n",
    "\n",
    "    df.columns = ['metric', 'timestamp', 'value']\n",
    "    # profiler = start_profiling()\n",
    "    df_features = extract_features(df, column_id='metric', column_sort='timestamp', column_kind=None, column_value=None)\n",
    "    # profiler_fname = '/tmp/test.%s.txt' % str(period)\n",
    "    # end_profiling(profiler, profiler_fname, 'cumulative')\n",
    "\n",
    "    end = timer()\n",
    "    calc_time = end - start\n",
    "\n",
    "    print(\n",
    "        'Time to calculate features for a timeseries with %s data points :: %.6f seconds\\n' %\n",
    "        (str(period), calc_time))\n",
    "\n",
    "    # Analyse log\n",
    "    with open(debug_log, 'r') as f:\n",
    "        loglines = f.readlines()\n",
    "\n",
    "    with open(debug_log, 'r') as f:\n",
    "        loglines = []\n",
    "        for i, line in enumerate(f):\n",
    "            if i != 0:\n",
    "                raw_line = line.rstrip('\\n')\n",
    "                new_line = raw_line.replace(',', ':', 1)\n",
    "                metric = new_line.split(':')[2]\n",
    "                try:\n",
    "                    timing = float(new_line.split(':')[-1])\n",
    "                    loglines.append([metric, timing])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    all_timings = []\n",
    "    unique_metrics = []\n",
    "    for i, line in enumerate(loglines):\n",
    "        if not line[0] in unique_metrics:\n",
    "            unique_metrics.append(line[0])\n",
    "    unique_metrics.sort()\n",
    "    for metric in unique_metrics:\n",
    "        metric_timings = []\n",
    "        for i, line in enumerate(loglines):\n",
    "            if line[0] == metric:\n",
    "                metric_timings.append(float(line[1]))\n",
    "                all_timings.append(float(line[1]))\n",
    "        total_time = sum(metric_timings)\n",
    "        number_of_times = str(len(metric_timings))\n",
    "        print(\n",
    "            '%s was calculated %s times which took :: %.6f seconds' %\n",
    "            (metric, number_of_times, total_time))\n",
    "\n",
    "    total_times = sum(all_timings)\n",
    "    print(\n",
    "        'Total function times took :: %.6f seconds' %\n",
    "        (total_times))\n",
    "    times_by = [10, 100, 1000, 10000, 100000, 10000000]\n",
    "    for multiple_by in times_by:\n",
    "        time_ts = total_times * multiple_by\n",
    "        print(\n",
    "            'Total function times for %s timeseries would take :: %.6f seconds' %\n",
    "            (str(multiple_by), time_ts))\n",
    "\n",
    "    reset_log()\n",
    "\n",
    "    return\n",
    "\n",
    "calc_runtime(100)\n",
    "calc_runtime(1000)\n",
    "calc_runtime(5000)\n",
    "calc_runtime(10000)  # with logging bad\n",
    "# calc_runtime(100000)  # Generates Memory Error:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
